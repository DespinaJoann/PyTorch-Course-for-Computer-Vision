{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPXfiDcheIk+VXwYTNQBu0e"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# Tutorial - `#03` Convolutional Neural Networks and Hyperparameter Tuning.üìäüß†\n","\n","---\n","**Lecture's TimeLine:**\n","1. [Convolutional Neural Networks (CNNs)]().üß†üîç\n","2. [Create a 9-layer CNN in `PyTorch` for `CIFAR-10` data - the s`tep-by-step` process]().üõ†Ô∏èüìä\n","3. [Working with pretrained models]().üöÄüì¶\n","4. [Two well known models: `ResNet` and `VGG`]().üè¶üìà\n","5. [Fine-tunning]().üéõÔ∏èüîÑ\n","6. [Optimization & Hyper-parameter Tuning (HPT)]().üî¨ü™õ\n","7. [Overall Sum Up and Further Explanation]().üéìüìö\n","\n","---\n"],"metadata":{"id":"Nafu_ME08PNL"}},{"cell_type":"markdown","source":["## [1. Convolutional Neural Networks (`CNNs`).]()\n","\n","<img src=\"https://cdn.prod.website-files.com/614c82ed388d53640613982e/646371e3bdc5ca90dee5331b_convolutional-neural-network%20(1).webp\" alt=\"Example Image\" width=\"600\">\n","\n","\n","\n","### What is a CNN in Deep Neural Networks?\n","A `Convolutional Neural Network` (`CNN`) is a specialized type of deep learning model used mainly for analyzing visual data like images. Think of it as a machine that learns to recognize patterns in pictures. CNNs are the driving force behind many advanced computer vision applications such as facial recognition, self-driving cars, and medical image analysis.\n","\n","### What is Actually a CNN?\n","\n","<img src=\"https://saturncloud.io/images/blog/a-comprehensive-guide-to-convolutional-neural-networks-the-eli5-way.webp\" alt=\"Example Image\" width=\"500\">\n","\n","A CNN is like a layered cake, where each layer has a specific role in processing the input data (like an image) to ultimately make sense of it. Here‚Äôs a breakdown of the layers in a CNN:\n","\n","1. **`Convolutional Layers`**: These layers are the core building blocks of a CNN. They use filters (small matrices of numbers) to scan across the image, detecting features like edges, textures, and patterns. Imagine a small window sliding over a photo, focusing on different parts to capture important details.\n","\n","2. **`Pooling Layers`**: After the convolutional layers, the pooling layers come into play. These layers reduce the size of the data, making it more manageable and less sensitive to slight changes or distortions in the image. It's like summarizing the information by keeping the most important parts and discarding the less important details.\n","\n","3. **`Fully Connected Layers`**: These layers are similar to the layers in a traditional neural network. They take the features identified by the convolutional and pooling layers and combine them to make a final decision or prediction. It's like piecing together a puzzle where each piece represents a part of the image.\n","\n","4. **`Activation Functions`**: Throughout the network, activation functions are used to introduce non-linearity, enabling the network to understand complex patterns. The most common activation function in CNNs is ReLU (Rectified Linear Unit), which helps the model learn more effectively by setting all negative values to zero.\n","\n","5. **`Normalization Layers`**: These layers, like batch normalization, help stabilize and speed up the training process by standardizing the outputs of previous layers.\n","\n","### How CNNs Really Work.\n","\n","<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQ707V-sM7sBqo_-vaVNBrhH8xBeenA6cW59eMtlDJrW5JLGFEa8rg7Nv_sOC_f0Qy86Jc&usqp=CAU\" alt=\"Example Image\" width=\"500\">\n","\n","1. **`Input Layer`**: The `CNN` starts with the input layer, which receives the raw data, such as an image. Each pixel in the image is represented by a numerical value.\n","\n","<img src=\"data:image/png;base64,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\" alt=\"Example Image\" width=\"500\">\n","\n","\n","2. **`Convolutional Layer`**:\n","   - **`Filters/Kernels`**: Think that you have a small stencil that you move over the image. This stencil (filter) looks at small patches of the image at a time. By performing a mathematical operation (convolution), it detects specific features like edges or textures.\n","   - **`Stride`**: The stride is the step size of how the stencil moves over the image. A larger stride means the stencil moves further each step, creating a smaller output.\n","   - **`Padding`**: Padding adds extra pixels around the edges of the image, allowing the stencil to cover more area and preserve the image size.\n","\n","<img src=\"https://media.licdn.com/dms/image/D4D12AQH2F3GJ9wen_Q/article-cover_image-shrink_720_1280/0/1688885174323?e=2147483647&v=beta&t=gFWxErTLLWBc6iRWDxCBRxkdJ7ob24cmjWZAOuKN9o4\" alt=\"Example Image\" width=\"400\">\n","\n","\n","3. **`Activation Function`**: After the convolution, the activation function (usually ReLU) is applied. This step helps the network learn complex patterns by making the data non-linear, much like turning on a switch for certain features.\n","\n","<img src=\"data:image/png;base64,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\" alt=\"Example Image\" width=\"400\">\n","\n","\n","4. **`Pooling Layer`**:\n","   - **`Max Pooling`**: This process takes the largest value from a small patch of the image, reducing the size but keeping the most significant information.\n","   - **`Average Pooling`**: This process averages the values in a small patch, also reducing the size but in a different way.\n","\n","   Pooling layers help to make the network more robust to slight changes and reduce the amount of computation required.\n","\n","5. **`Stacking Layers`**: The network stacks multiple convolutional and pooling layers. Early layers might detect simple features like edges, while deeper layers detect more complex patterns like shapes or objects.\n","\n","6. **`Flattening`**: After multiple layers of convolutions and pooling, the resulting data is flattened into a long vector, which is then fed into fully connected layers.\n","\n","7. **`Fully Connected Layer`**: These layers act like a traditional neural network, where every neuron is connected to every neuron in the previous layer. This part of the network combines all the learned features to make a final prediction.\n","\n","8. **`Output Layer`**: The final layer produces the prediction. For classification tasks, it often uses a softmax activation function, which turns the raw scores into probabilities for each class.\n","\n","### Example Workflow:\n","Imagine you're trying to teach a CNN to recognize handwritten digits (0-9):\n","\n","1. **`Input`**: A 28x28 pixel grayscale image of a digit.\n","2. **`Convolutional Layer`**: Apply 32 filters of size 3x3, scanning over the image to detect features. The output might be a 26x26x32 feature map (if no padding is used).\n","3. **`ReLU Activation`**: Apply ReLU to introduce non-linearity.\n","4. **`Pooling Layer`**: Apply max pooling with a 2x2 filter, reducing the feature map to 13x13x32.\n","5. **`Convolutional Layer`**: Apply 64 filters of size 3x3, creating an 11x11x64 feature map.\n","6. **`ReLU Activation`**: Apply ReLU again.\n","7. **`Pooling Layer`**: Apply max pooling, reducing the feature map to 5x5x64.\n","8. **`Flattening`**: Flatten the feature map to a vector of size 1600.\n","9. **`Fully Connected Layer`**: Use a dense layer with 128 neurons.\n","10. **`ReLU Activation`**: Apply ReLU.\n","11. **`Output Layer`**: Use a dense layer with 10 neurons (one for each digit) and a softmax activation to get probabilities for each class.\n","\n","\n","### A small Recap:\n","Convolutional Neural Networks (CNNs) are primarily used for image processing and pattern recognition. The main layers in a CNN are:\n","\n","1. `Convolutional Layers`: Apply filters (kernels) to extract features from the image.\n","2. `Pooling Layers`: Reduce the dimensions of the features to limit computational load and overfitting.\n","3. `Fully Connected Layers`: Connect every neuron with every neuron from the previous layer and are used for final classification.\n","4. `Activation Functions`: Usually, the ReLU function is used to introduce non-linearity.\n","\n"],"metadata":{"id":"J3vBOrpcqJrg"}},{"cell_type":"markdown","source":["Before we dive into the new coding staff and explaining them with great detail, let's write down the staff that already know:"],"metadata":{"id":"sGUKLDi_vUWP"}},{"cell_type":"code","source":["# Import the relevant libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torchvision import models\n","from torch.utils.data import DataLoader, random_split\n","import torchvision.transforms as transforms\n","import torchvision.datasets as datasets\n","\n","# Define the training and testing transformations\n","transform = transforms.Compose([\n","\t transforms.Resize(224),  # ResNet expects 224x224 input\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Load the CIFAR-10 dataset.\n","train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Split the training dataset into training and validation sets (80% train, 20% val).\n","train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","# Create the Dataloaders\n","train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"],"metadata":{"id":"xKaL4PaEvZWS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["In `PyTorch`, specifying the `device` where computations will occur is crucial for optimizing performance. The line of code:"],"metadata":{"id":"G8XT7duvfGQw"}},{"cell_type":"code","source":["device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","device"],"metadata":{"id":"dyR7BqmZfHsv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["is used to check if a `CUDA-capable` `GPU` is available on your machine. If it is, the code sets the `device` to `'cuda'`, allowing your model to leverage the `GPU`‚Äôs parallel processing power, which can significantly speed up computations, especially during training. If a `GPU `isn't available, it defaults to `'cpu'`, which ensures your code remains functional even on machines without a `GPU`.\n","\n","- **`Performance Optimization`**: `GPUs` can handle many operations simultaneously, making them much faster than `CPUs` for tasks like training deep learning models. By using the `GPU`, you can drastically reduce the time required for training and inference.\n","\n","- **`Code Flexibility`**: Using the `device` variable allows your code to automatically adapt to the available hardware. This means you can run the same code on different machines with varying hardware configurations without needing to manually adjust settings.\n","\n","With other words, this line of code helps your program decide the best hardware to use, ensuring that your computations are performed efficiently and effectively."],"metadata":{"id":"upSukxOmKEeH"}},{"cell_type":"markdown","source":["Let's rewrite the training and the testing procedures, that we created in our previous tutorial. The only change, is the new device argument.\n","\n"],"metadata":{"id":"Y8Vj1W6nveda"}},{"cell_type":"code","source":["import torch\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device):\n","    '''\n","    Train the model and validate its predictions.\n","\n","    Parameters:\n","    - model: The neural network model to be trained.\n","    - train_loader: DataLoader for the training data.\n","    - val_loader: DataLoader for the validation data.\n","    - criterion: Loss function.\n","    - optimizer: Optimizer for training the model.\n","    - num_epochs: Number of epochs to train the model.\n","    - device: Device to train the model on (CPU or GPU).\n","    '''\n","    model.to(device)  # Move model to the specified device\n","\n","    for epoch in range(num_epochs):\n","        # Training loop\n","        model.train()  # Set the model to training mode.\n","        running_loss = 0.0\n","        for inputs, targets in train_loader:\n","            inputs, targets = inputs.to(device), targets.to(device)     # Move data to the specified device.\n","\n","            # Forward pass\n","            predictions = model(inputs)                                 # Compute the model predictions.\n","            loss = criterion(predictions, targets)                      # Calculate the loss.\n","\n","            # Backward pass and optimization\n","            optimizer.zero_grad()                                       # Clear old gradients.\n","            loss.backward()                                             # Compute new gradients.\n","            optimizer.step()                                            # Update model parameters.\n","            running_loss += loss.item()                                 # Accumulate training loss.\n","\n","        # Validation loop\n","        model.eval()                                                    # Set the model to evaluation mode.\n","        val_loss = 0.0\n","        correct = 0\n","        total = 0\n","        all_labels = []\n","        all_predictions = []\n","\n","        with torch.no_grad():                                             # Disable gradient computation.\n","            for inputs, targets in val_loader:\n","                inputs, targets = inputs.to(device), targets.to(device)   # Move data to the specified device\n","\n","                predictions = model(inputs)                               # Compute the model predictions.\n","                loss = criterion(predictions, targets)                    # Calculate the validation loss.\n","                val_loss += loss.item()                                   # Accumulate validation loss.\n","\n","                _, predicted = torch.max(predictions.data, 1)             # Get the predicted class.\n","                total += targets.size(0)                                  # Total number of samples.\n","                correct += (predicted == targets).sum().item()            # Number of correct predictions.\n","\n","                all_labels.extend(targets.cpu().numpy())                  # Collect true labels.\n","                all_predictions.extend(predicted.cpu().numpy())           # Collect model predictions.\n","\n","        train_loss = running_loss / len(train_loader)                     # Calculate average training loss.\n","        val_loss /= len(val_loader)                                       # Calculate average validation loss.\n","        val_accuracy = 100 * correct / total                              # Calculate validation accuracy.\n","\n","        print(f'Epoch {epoch+1}/{num_epochs}, Training Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%')\n","\n","        # Calculate and print confusion matrix\n","        conf_matrix = confusion_matrix(all_labels, all_predictions)\n","        print(f'Confusion Matrix:\\n{conf_matrix}')\n","\n","        return model\n","\n","def evaluate_model(model, test_loader, device):\n","    '''\n","    Test model's accuracy of predictions on unseen data.\n","\n","    Parameters:\n","    - model: The neural network model to be evaluated.\n","    - test_loader: DataLoader for the test data.\n","    - device: Device to evaluate the model on (CPU or GPU).\n","\n","    Returns:\n","    - accuracy: Accuracy score of the model.\n","    - conf_matrix: Confusion matrix of the model's predictions.\n","    '''\n","    model.to(device)                                                     # Move model to the specified device.\n","    model.eval()                                                         # Set the model to evaluation mode.\n","\n","    all_labels = []                                                      # Stores the true labels from the test set.\n","    all_predictions = []                                                 # Stores model's predictions for the test set.\n","\n","    with torch.no_grad():                                                # Disable gradient calculations for evaluation.\n","        for inputs, labels in test_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)        # Move data to the specified device\n","\n","            outputs = model(inputs)                                      # Get model predictions\n","            _, predicted = torch.max(outputs, 1)                         # Get the index of the max log-probability.\n","\n","            all_labels.extend(labels.cpu().numpy())                      # Collect true labels.\n","            all_predictions.extend(predicted.cpu().numpy())              # Collect model predictions.\n","\n","    # Calculate metrics\n","    accuracy = accuracy_score(all_labels, all_predictions)\n","    conf_matrix = confusion_matrix(all_labels, all_predictions)\n","\n","    return accuracy, conf_matrix\n"],"metadata":{"id":"xC2YNp6FvnXc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Beautifully! Now we are ready to start with the new staff!\n","\n","## [2. Create a 9-layer CNN in `PyTorch` for `CIFAR-10` data.]()\n","\n","Here is a `step-by-step` process to create a 9-layer CNN using `PyTorch`.\n","\n"],"metadata":{"id":"nRmMso3OZydV"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"4CmDsVxa7peb"},"outputs":[],"source":["class MyCNN(nn.Module):\n","    def __init__(self):\n","        super(MyCNN, self).__init__()\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","        self.pool = nn.MaxPool2d(2, 2)\n","        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n","        self.fc2 = nn.Linear(512, 10)\n","        self.dropout = nn.Dropout(0.5)\n","\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n","        x = x.view(-1, 128 * 4 * 4)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n"]},{"cell_type":"markdown","source":["##### **Break the code ü™®.**\n","\n","`MyCNN` is a convolutional neural network consisting of convolutional layers for feature extraction from images, pooling layers for dimension reduction, and fully connected layers for final classification. The use of batch normalization and dropout helps improve performance and avoid overfitting. This architecture is designed to work well with the `CIFAR-10` dataset, although further improvements can be made depending on the needs.\n","\n","Let's explain the code in great detail:\n","\n","#### **1. Class Definition - the network.**\n","\n","```python\n","class MyCNN(nn.Module):\n","    def __init__(self):\n","        super(MyCNN, self).__init__()\n","```\n","\n","We create a class `MyCNN` that inherits from the `nn.Module` class. This allows us to define the layers of the neural network and how data flows through them.\n","\n","#### **2. Convolutional Layers and Batch Normalization.**\n","\n","```python\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(32)\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(64)\n","        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n","        self.bn3 = nn.BatchNorm2d(128)\n","```\n","\n","- **self.conv1 = nn.Conv2d(3, 32, 3, padding=1)**: The first convolutional layer.\n","  - **`3`**: Number of input channels (RGB image with 3 channels).\n","  - **`32`**: Number of filters (kernels) applied, producing 32 feature maps.\n","  - **`3`**: Filter size 3x3.\n","  - **`padding=1`**: Adds one pixel around the image to maintain dimensions.\n","\n","- **`self.bn1 = nn.BatchNorm2d(32)`**: Applies batch normalization to the 32 output channels of the first convolutional layer for training stabilization.\n","\n","The following lines follow the same pattern:\n","- **`self.conv2`** and **`self.bn2`**: Second convolutional layer with 64 filters and batch normalization.\n","- **se`lf.conv3`** and **`self.bn3`**: Third convolutional layer with 128 filters and batch normalization.\n","\n","> ##### **üìì Note:** Why 32 input kernels? How to choose the number of filters for your convolutional layer and why is it so important?\n",">\n","> Choosing `32` kernels for the first `convolutional` layer in a `CNN` is a balanced decision that enables effective feature extraction while managing computational cost. It allows the network to capture a variety of low-level features such as edges and textures, which are crucial for initial image understanding. This number is empirically validated by common practice in successful architectures (like `VGG` and `ResNet`) and provides a good trade-off between model complexity and performance, particularly for datasets like` CIFAR-10`. Starting with `32` filters and progressively increasing the number in deeper layers supports hierarchical feature learning, reduces the risk of overfitting, and ensures the network generalizes well.\n","\n","#### **3. Pooling Layers.**\n","\n","```python\n","        self.pool = nn.MaxPool2d(2, 2)\n","```\n","\n","- **`self.pool = nn.MaxPool2d(2, 2)`**: Max pooling layer that halves the dimensions of the image using a 2x2 window with a stride of 2.\n","\n","#### **4. Fully Connected Layers.**\n","\n","```python\n","        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n","        self.fc2 = nn.Linear(512, 10)\n","        self.dropout = nn.Dropout(0.5)\n","```\n","\n","Let's explain each line:\n","\n","- **`self.fc1 = nn.Linear(128 * 4 * 4, 512)`**: First fully connected layer.\n","  - **`128 * 4 * 4*`*: Number of inputs (after applying convolutional layers and pooling, the image has dimensions 4x4 with 128 channels).\n","  - **`512`**: Number of outputs.\n","\n","- **`self.fc2 = nn.Linear(512, 10)`**: Second fully connected layer with 512 inputs and 10 outputs (for the 10 classes of `CIFAR-10`).\n","\n","- **`self.dropout = nn.Dropout(0.5)`**: Dropout layer that randomly drops 50% of the neurons to avoid overfitting.\n","\n","#### **5. Forward Pass.**\n","\n","```python\n","    def forward(self, x):\n","        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n","        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n","        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n","        x = x.view(-1, 128 * 4 * 4)\n","        x = F.relu(self.fc1(x))\n","        x = self.dropout(x)\n","        x = self.fc2(x)\n","        return x\n","```\n","\n","This method describes the flow of data through the network's layers:\n","\n","- **`x = self.pool(F.relu(self.bn1(self.conv1(x))))`**:\n","  - Applies the first convolutional operation.\n","  - Applies ReLU activation.\n","  - Applies batch normalization.\n","  - Applies max pooling.\n","\n","- **`x = self.pool(F.relu(self.bn2(self.conv2(x))))`**: Similarly, applies the second convolutional operation, ReLU activation, batch normalization, and max pooling.\n","\n","- **`x = self.pool(F.relu(self.bn3(self.conv3(x))))`**: Similarly, applies the third convolutional operation, ReLU activation, batch normalization, and max pooling.\n","\n","- **`x = x.view(-1, 128 * 4 * 4)`**: Reshapes the tensor to 2D (batch_size, 128 * 4 * 4) for the fully connected layers.\n","\n","- **`x = F.relu(self.fc1(x))`**: Applies the first fully connected layer and ReLU activation.\n","\n","- **`x = self.dropout(x)`**: Applies dropout.\n","\n","- **`x = self.fc2(x)`**: Applies the second fully connected layer for the final output.\n","\n","#### **How Many Layers the Network Has?**\n","The `MyCNN` has the following layers:\n","\n","1. **`3 Convolutional Layers`** with batch normalization.\n","2. **`3 Pooling Layers`**.\n","3. **`2 Fully Connected Layers`**.\n","4. **`1 Dropout Layer`**.\n","\n","In total, the network has 9 main layers, plus the activation functions (ReLU) and batch normalization.\n","\n","\n"],"metadata":{"id":"XBZDlzyeaMZ7"}},{"cell_type":"markdown","source":["\n","## [3. Working with Pretrained Models.]()\n","\n","<img src=\"https://i0.wp.com/syncedreview.com/wp-content/uploads/2020/06/Imagenet.jpg?fit=1400%2C600&ssl=1\" alt=\"Example Image\" width=\"600\">\n","\n","\n","### The `ImageNet` Dataset.\n","`ImageNet` is a comprehensive visual database designed for developing and benchmarking computer vision models. It consists of millions of labeled images across thousands of categories, making it a valuable resource for training and evaluating visual recognition systems.\n","\n","##### **Importance:**\n","`ImageNet` is pivotal for supervised computer vision tasks because it provides a vast array of labeled images, allowing models to learn rich and generalized features. This extensive dataset helps in creating models that perform well on diverse and unseen data.\n","\n","##### **Ethical Considerations:**\n","When using datasets like `ImageNet`, it‚Äôs crucial to address ethical concerns such as privacy issues, as the dataset might include images of individuals without their consent. Additionally, the dataset can contain biases that may be reflected in the models trained on it, leading to unfair or skewed results.\n","\n",">  **What is `torchvision.models?`**\n",">\n",">`torchvision.models` is a module within the `PyTorch` library that provides a collection of popular pretrained models. These models are available for various tasks like classification, segmentation, and object detection. Users can directly use these models or fine-tune them for specific tasks.\n","\n","\n","### Transfer Learning.\n","\n","<img src=\"data:image/png;base64,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\" width=\"500\">\n","\n","#### **What is Transfer Learning?**\n","\n","**`Transfer learning`** is a powerful technique in machine learning where knowledge gained from solving one problem is used to solve a different but related problem. It‚Äôs like using the skills you learned in one job to perform a different job more efficiently. This concept is particularly useful in deep learning, especially when working with complex tasks like image classification.\n","\n","#### **How Does Transfer Learning Work?**\n","\n","<img src=\"data:image/png;base64,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\" width=\"600\">\n","\n","1. **`Start with a Pretrained Model`**:\n","   - **What‚Äôs a Pretrained Model?**\n","   \n","    - Imagine you have a model (a `neural network`) that‚Äôs already been trained on a massive `dataset` like `ImageNet`. This model has learned to recognize various patterns and features from millions of images.\n","    \n","    - **`What Does It Know?`** It knows how to identify basic features like edges, textures, and shapes, which are useful for many different types of images.\n","    \n","> A `pretrained model` is a `neural network` that has been previously trained on a large `dataset`, such as `ImageNet`. These models come with learned `weights` and `biases` that capture general features from the original `dataset`. They can be used as a starting point for training on a new, possibly smaller dataset, often leading to better performance and faster convergence.\n","\n","2. **`Adapt the Model to Your Task`**:\n","   - **`Fine-Tuning`**: Instead of training a model from scratch (which requires a lot of data and computing power), you can start with the pretrained model and then fine-tune it on your specific dataset. This involves training the model a bit more on your data so it learns the details specific to your task. *Later on this tutorial we cover with more detail what is `fine-tuning` and how it works.*\n","   - **`Modifying Layers`**: Often, the `final layers` of the model are changed to fit the new task. For example, if the original model was trained to classify 1,000 types of objects (like in `ImageNet`), and you want it to classify only `10` types of objects (like in `CIFAR-10`), you‚Äôll modify the final layer to match your new classification task.\n","\n","3. **Benefits**:\n","   - **`Faster Training`**: Since the model already knows how to extract useful features, it learns much faster and requires less data.\n","   - **`Better Performance`**: Leveraging the learned features from a large dataset usually results in better performance on your specific task, especially if you don‚Äôt have a lot of data.\n","\n","#### Why Use Transfer Learning?\n","- **`Efficiency`**: Training a deep learning model from scratch can be very time-consuming and computationally expensive. `Transfer learning` allows you to leverage existing models to save time and resources.\n","- **`Improved Accuracy`**: `Pretrained models` often have a strong performance due to their exposure to diverse data. `Fine-tuning` them for your task can lead to better accuracy compared to starting from scratch.\n","- **`Practicality`**: For many applications, especially with limited data, transfer learning provides a practical and effective way to build high-performing models.\n","\n","### Example in Practice\n","\n","1. **`Training from Scratch`**: Suppose you want to create a model to classify dog breeds, but you don‚Äôt have enough dog images to train a model effectively.\n","2. **`Using Transfer Learning`**: You can use a model pretrained on `ImageNet`, which has learned to recognize a wide variety of features. By adjusting the final layer and fine-tuning it with your dog images, you quickly adapt the model to your specific problem.\n","\n","`Transfer learning` allows you to build powerful models efficiently by building on the knowledge acquired from large datasets, adapting it to your particular needs, and achieving great results with less data and effort."],"metadata":{"id":"k2cHTO0eaRn3"}},{"cell_type":"markdown","source":["## [4. Two well known models: `ResNet` and `VGG`.]()\n","\n","### `ResNet` (`Residual Network`).\n","\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*Y-u7dH4WC-dXyn9jOG4w0w.png\" alt=\"Example Image\" width=\"900\">\n","\n","\n","#####  **What is `ResNet`?**`\n","`ResNet`, short for Residual Network, is a type of deep neural network designed to solve problems encountered when training very deep networks. It was introduced in a 2015 paper and is known for its ability to train extremely deep models effectively.\n","\n","<img src=\"data:image/png;base64,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\" alt=\"Example Image\" width=\"900\">\n","\n","### Key Features of `ResNet`:\n","\n","1. **`Residual Blocks`:**\n","\n","<img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASgAAACqCAMAAAAp1iJMAAACFlBMVEX///8AAAD4+Phubm7X19fR0dGGh4aysrJISEg3Nzarq6ujo6Pz9PP///0AACzat4HK4/z659I6AADs9v+rzuL3//////oAADD/9eHc3Nzu7u6+nWDk5OQAAFAALmXy//+hhVJXMwC/v7////D+798cAAC2jkdTiryZeE8AIWmkaUESSmd5PE3Y7/plZWWam5ogIB8ATXMAABMtAADUpIMAAGMAF0zd7f94eHgAADwAAB9FAACawdhOEAC93OwlAAAsLCtRUVA6OjrXu5kSAAD33MLo07QAAEcAAAgqAADl/////+sAABv//9+Ho9HDkHHozZzB2Pc8PERUS064jXdJTV0hO2GRpriOZD5WeqRdNSOVtdRwSyg2GgBbZG4AEzSzj2ZCZY2ymXqPgHGIrsuruMbQxr/Fz9tgAACKVS8pSFxqXEUzRGUIMTk6MicdEwxCKAATMkwiCydjSTkASoiFTQDBn29tPABsnr+ZZCkjVIiddD4yRUZ6lbSgzfNgHQBjh509bXx+KwCEZktNco9DQFthRD/YwqVIX3uNgFeGkakDJT5ZU2S3raRFJUFMJABLbmdcPgBIIBsNLiqJoLwwcKJxeZAAMHxCaolaPTeMb2a4pJHEuKU4EwBtVDJsEAA1Gyd5SwBuZ0KeXSycXwBkKgBeKR+ceoA8ABOPX0w5JRMfITJGNUVDaZ+GVGBKVHxugKYaMBAxjHLzAAAR5klEQVR4nO1di18TWZa+N5XKgyRAhBRJKGWtSjfpcVKVRkeKh5AHiSBq046CCsP7oWLTunSjwuCwjd24zjLOzIJrN9rb7o776J7dnv0P996qJORRhEpSFYuY76chqXe+3HvuOeeecy4AVVRRRRVVVFFFFVVUUUUVVVShAQzv+gGOCGhIv+tH0BViVzju1z3gajh8rT5jhxGS7+iR9AnK44fDARDtGyEbMnZUicqG4zq84b45mr25SlQO2LG24GzO1ipRuYj95mJOg6oSlQuHf/zHicbsrVWicjA55Yr23q/P2uqBxnfyNHqFzzjdVA8oP7y7kD3qRSwphDE4wmSymRmSNHpo73unjsbDHDcK3DMEwWUKdCMMEyI4Dv3DCFsioSCUELSGwwRvRpS9d4xlQ67rGexeL017PKSZNxGcJYQps3KCzUjb38ET6gQKhLmd9pA1pnAE0RXiTMx7ylYBox5tZExh1LxChO09JKtQ9cDgYUy4bRE1Xo2eSKcoSo/ykrwVQgvvUf95dIuiFU7azCERz783TpqSNHMGcWVh1HsY3cKL1QNS/FskDGYksPiKF+1kkOch+leSFUObIBQqXbITov7NlXgVA49GwcoWVh6RKBW+ow1CU0VbOYQKDUqEAXVAsxoX0ilwk1JJG6IJyFVw/yPUaVAimCCsUe1i2sFQFJAeVdyJco/gFSChe0lFRqzFIAKLO88qr6eaYUTvdo0NCqYy4qBO5gnp3Qlvg2Vt9AdKI3sY6tuoscGyGhJ5xDanbz1BP0ShkVTPbUpHRKE2pWOm9EQUYkq/Y1+hRMXnXBmfqZpAIafnJ8oQCurW9aKIqCHYk3zb/HFLxi7n6Zzp9nw4RAf3wnAhVysnFBHls6XmiZNEnTkutSznMTWJAgzkC7lcGZFLFDWPWPEtoDdkA/pgRp8oI2LFxzDkAiLKNb/gAr6rHegDSBCFdqFDSVfqnAB+Z5hfyLndoVadSa9BDTJE3WoFjtvDDajDBZzH7izCbhCvrQdROH4P3r3Q/NlSBE61TH/eb53CR2OiJtu4e00BZ98o6qRt9b6T9xfhLIj9/TK825J9u0OJMkQsan01dSHT9ZpPuNz3OnvA5Bfgy10AVk60xJvq2QcPwSX4GDT3j4I4bERdTyIBE2VsAGzXZfBoygX8q2BtFYBox4XY6amGXKX/cD8BqVNXggxRcRiI/3bpIftg9tIH6wyz1xkQiZqViEIyytfVnSmjfCT5u3UQ7Qy4n4+ytzZIJgp7Yh/05NxMCVFAgLr0pMsQNdh1ufnGyqqzr/4SfCoQwosGRBTwXxTuDbdIRJ3LJCoaHCcG1oH7+eWhpoC765pAEC8CRRNFQ1PJ30oDyI16a/9w83F8YuaEa/CYFJSIiHKfm9tGQlyOKHfXLABfrQMweWpzF7BvH4o7iiYKyXM9Nik5oqKwI+A+CdEXXju7QM/PuZAwZ0/eIYiRhlTXQ51L1KIRUey5DW8UIqJivW2oH042LdCeEVesr1iivLpsUnJEuZefuMDV++iLspvBYGgdxL9uZ8eemPl7q6AO7fItN6I9n4ujnu+bHrC1FHr6jzs4gBiNlYCdDgVDf3M5/1osUahJ6VA/P0zhpBLdYKgT6UZnzqeN92nnOaT37IPWjHNkoIgoWo8OF6W2nvP0U5Op92HeY7agXCPKgLKxnwspeqayQrFR7Nvma3I17QzER1z5D1BKFKND9VxXbpYkDDq0+HRJFFI6NX6OwqFPohj9efD0MgtT5HHlgw3WmMsIpQRYdOfAY2B5oXCak9efkCouggDHcKoWeyADHQqp4uDReAbcUBbl3JFpQngPVQMLx4FRwWoNDVoZxg57AvhB9zIzNmPP1GfqIKKGcjL7igSniUfYN2OJSLBGHoPoetbunA2l4yCi6mpVIsqmhTSnZuY8tP/3Cx6PZ+9au/ufsqckqc2CppSUQHOizFrpd+z1VfzHAcDk5Zyd8VW1O1+KKGq+wWkLYJsZv4pE4aku6aUEkFoNe75zCReI+w+5c9zs2Kcq3y5FlPv5H3vhQxCFny1hJycm6u9+hbZ/+FFD3gscBlqrgI2hZJvf+hi1Hsc8wzALeGKSwb+sw5/fkVQ49on6U/+oo+FSXysA0209aUSdKI0ooJV+4E9ONjbfQC/U3iKEN4D7Xlt4B288s6ry7faJOrmLrw8DDhAbmFWTKG08Le6T93ECdDcAjxIiahJOuZx/TkjxoY9UFlJpRLWKNxMxqiZR2ihSQ7UjZvM2Dsn5MkEUdR0+eZtUqIY6Lqh7vyyizsDE9dUjKkKUdr48qOtTybdfJQc9dgzuJjfGm7Qlagg+lj5ioiYRa4MPSiWK08R/EBtIaUrJFoWbFEy1qPOaEfUcE+V4BEfMex0BUNdZD+Lw7vbAP+uTqMnV1DzSh9KUEXCs7ToHOlMySuUbpohiZ7rxHzR6WATU8+Mv2tHAu3htLl6q3aS6DUPt7QDn6+7U55Un0hNOTrnAVu/vJaXhzK7sucVD+yI2hNpEuQf6n/nX93++uDhb6w/CiQtIDYRtd9FPTPlzK0CVACOJ9EEjIDXlioiofcU4QaQHoA7+uQc7WhBcwID/oG3umypZYBLooDUMw1ZtpyUEq5ZXx1j5W86m6A11b8GLWpO2c2+m0IG7WBPP83MgbuJNpViU7K+zm4/7m/YSricDr1jWR9vpm3xE1czAzm4Qf32HL8n0jr3IDJ10XM0tvVYieM0bFBDyySjKD5+4pp+WqIGArZHMj3MlXi8XXs0b1CF6FLvZxl0rKBVAARwqXw+D1zw6wJI/F9d5E6rtETkEHmMxICFZ1HnKvXEhIe/u+LdLuSUKtYS5zBOgir1M+b0Hzh8atwYmVFV6DoENMmQZoTymIG/f9uFas9G+YZVH83zQaZBGXqIu9UH40oVGPgj/RZWnUgJ9hv3gI21aPkfh0CtRdr0FvOqVKK2DGwqGXoli9FaCXxFRdiZlLKy8zLSPfN8eGjKdDsVEmfUWIFVsqmxyJljlDNC05yrksmWAIqLS4ohSqbLnpc9aESWECrlsGSCTAfod+urRHRdwC+1gazE84gLOFw2A3QuPCy9amk/Nfze+ALaWOwUxRgYT5UO75oBTQEYqPif+XXikAfiezS9u5PjNFRN1iKlXfsi0qC93ATt2th3UdVyIwpFXr9dxqqxjcoLxw3VXM7zPf382sLVcy4s+CkSUY3KcmYaPB7taATonsAWfzT/fBbHevvFnhafKpg7UW4aVDFErx1ti9/obHdd3qVuXUeM6jxMb2bezYPCDx6AZMegcwPl60sG4RWHd/l/XQfNwA3X7huNNKxZqgdiAnHWvlKjyhCYWAhmiYrAx+nSzlT3XfQleI4jFWjFV9s0NQxzWy2aAUq8E4vQ6Ps95upG9dYfgFktIlRWhv2BXGaKotw/XWuuG47WBS3AHGbILOAOU8rdZP1+XzQCl1ibmcE4x+wCddcHdtYGtX1dpROlu0JMd9Zp/+0Oj84dvVgF7S+o+OFX2dKMHK1MpojpSWeruY91i1wMrn33bCqg30kxGaUSlDXqG5JC79eJA169Be61ZjqgYPB9gx+Asks1wg5950hLvrMcT9PBOYypVdghuPMPH4s725pTtexxF5vxNbQ9OtEXn/NwSk03eU0pUMCXL2TediXCA5vNyXhX8+NSD8wHg0NYNIkcUi8Ni5kfw7zc/I9gWcMkR5+luA+0/3oKL2FDbSBF4JYhTFqwtAHzbwtwWVkBvi0qWkyf4hfQyJWlQSJR3X5Y75pMufzyO5OASxLEW8+ipPrmocnxFJpTaekNtiJzJ43kDCtyvD3VjKySqJu2pKJFwZAlIRPlEc4ryAlZcTssJL3sN+Bjqam3AC2gXyJuqWzyUEsXirteU366rqz10XkQhUWm5so61X7nEyJzafzvRLj3GlAtEO2bQm1kkGxB2wb8PtzzA7y70YQHZ3KSB57MA78GhGRD2w39JpRmg+147h/8jF1iBuIDAcLvD3xEAcdTbonCinr3dFEh0vV+cagGf4BiwD4+3gME//Y+SmxQIXbpZatJ8LCJRX+EYVNT1fF24c/9lF0T7UeOu6/80m6g4fCyWjlEfuiQqPVsPE8V2bQCRKGevOJWziuvAYP0/hyj2dy/B2nCpM8hy0CNRxvQY8yyiZg1iws9BRIGVDvvJVi2evMwqsCKiuGDaB7HrffkFEuhrJ9rdbxMRcXJE1WKiYn3jsrVOSoYNWopCuLjTlBBFZhjEIlFI8Z3/Hk60I6m+YSRnRkH0Yo9EFHXrY6RoYaLq4A7W727Dj3N8FmqAJooCl1zkq1Ao8IRbMoISHdNIG3BML/208eop0pb2LMEr4/Ug/jXiJI5XcN0KB3fA1SctgJ1Zuh/AhkFuLtA7BK1drQuz7PxLKsnWkb0m3b7pYsD6y0qn2kEuJUG7YFcPLCkSn307pUHCa/HQjChDxFrSMByLdB9+UBmhGVGCDuvXlAKtiOL1V0KjNGhElPaBfOWGNkSZKowno11cA9SgtjQRKownpERZCUhYVa4C6bVWmnzCXQRD3SlKBlbYeIdBi0Sp2aC8AuR0v4ZOERAQT/nDmwuDDeotElEl4CalXqAXY63cJQmF0iyyNBiYMAxXnnRKglYpNsDLh2BYx4uclAavmbNAC2cutbsYPEjWEZXbmpDktQgmwQKDpYTmGIymCAxW8ILFBg4KUrfzEEWPfHbSFIJBgtRhlWnVkL5uUk0xSqeB5DkIgwKpS73JkOdTQbBJPBmkxWBthRUvMtgZUxji5dR1Fm2fwlam22+r6Ox+Q6K3Jb0HyalKu3AI+XbSJnIEuRpdkeR4JXAJCD1gKztx/ZNi/aXmhJ6ZJEoKIfSaDl47lWbMNpNFtHk4ntFbwCHl3zAzm51zZrN582Kj8+vsmS7qP4qcqiAiUsvxJCxYGln8tJCVsGinjSRjruEJSyKbMcjZdEdRGh59gV8dAPhzs9SjWTVI/lPhdD1OYKVNJhPSzNEr+vIRTpBai0Bw4XAkmJ7taeVMNjOpewVgsCsR1uX8a27zGfyvjG2OXypsYSET7m7BYFD8jyS5JcFNKGIJhznCxPO2GoYh6SNku+EJZxF1YriQx0N7aGBHr2Lj+UvGfGoGUZSHxgd5k4emI5yQRcksMW+QBzUhRNQRNkMmk+XafoFbFvXfS/0Xd0D8ddsVcchbeZJ+bAZRzvCPwZ8awZm+n67kFFvkE8EvSaIkoW6O6C7RQDnYB6d4njd9CtgxaYhzj8Ed4Pw2Md5FM0pzZnW9+OuJRhAdbs+tmOBJSO3kqCcEpT7GWHSpPipBHK/ULLwIAPfNRACa83nn3HJSrscz62Rmyaho7/C27AI4gJOYSXgPPKnpgCPLE17ATUKKKBD/EaYUqvhxiShqWlS2fhjHr/sR79Oft8mrWnTCZSvSZY+Ejry15u5Ktp19otgxeDcZL5tqUXZcY8r+yx5votaUBOfz/pfyYUYMDCdVImNEdxkrhWPlRPJ7JmUUcPg3pvuSFXKiX2QEfWR1PffyiB/m1qESQYagQNI0TRLQerR5cswvAPfblDnnuJ7QpyanWih/X6IE3srLjFMyiWI314H7e7gjf307H5JUJ/7oCiYRzmMTcys/73ecFaxHsTOL8AauLAqldMMPD9ajnMIyHMUlmqBwgPFsMNZAm/GI04S+9d5ScCNtTHPiMD5Kqq+Miy0zqE2xtzLGtAyipFLM1HyiIrMsDipLIK4/e3SQqf9Qm7kD2FBmlWXH/xZoJB9Y+L2tnBV41Eb855yf+XaJ30fzCvnvBivZgbJ1pcasVyhRYDKz88UPGPmVI60Ebs/0FXT1veUrIy0SUaKbMLp+pIRVCqr5zBNIqz79f01ocHzUP7J9GpmP+2W6z2qRkHL0kLaUwNlAokw3zmpSr555JYBk7DQ02hnMVbLw+5zZvAfVXEqgEuANBq0wFBSLviWXEhAw1FycoiKQVitYbikBnHlcJQpDqhUsvpWIiuFsfspjEIk6g2TVVq8m2YVHDvu1gqWlBMA0vBJeOh8QNXP3837LxGJ11MPYrxVMzUseLnrbtuBFdiLOsfdtzzWUuiRTpYA/wrMJZYVX5SDzykXlxslVUUUVVZQH/w/nbLfD5UI6LgAAAABJRU5ErkJggg==\" alt=\"Example Image\" width=\"300\">\n","\n","\n","   - **`Concept`:** ResNet uses residual blocks where each block includes a shortcut (or skip connection). This shortcut allows the input of the block to be added directly to its output.\n","   - **`Why It Matters`:** These shortcuts help the network learn identity functions, making it easier to train deep networks. Instead of learning the complete transformation, the network learns the difference (residual) between the input and the desired output, which simplifies learning.\n","\n","2. **`Skip Connections`:**\n","   - **`How They Work`:** In a residual block, after passing through a few convolutional layers, the original input is added to the output. Mathematically, if \\(F(x)\\) is the transformation learned by the network, the output is \\(F(x) + x\\).\n","   - **`Benefit`:** This addition helps gradients flow more easily during training, preventing the vanishing gradient problem where gradients become too small to make progress.\n","\n","3. **`Bottleneck Blocks`:**\n","   - **In Deeper Networks:** For very deep ResNets (like `ResNet-50`, `ResNet-101`), a bottleneck block is used. This block reduces the dimensionality of the input, processes it with a 3x3 convolution, and then restores the dimensionality.\n","   - **`Structure`:** It usually consists of three convolutional layers:\n","     1. **`1x1 Convolution`:** Reduces the number of channels.\n","     2. **`3x3 Convolution`:** Extracts features.\n","     3. **`1x1 Convolution:`** Restores the number of channels.\n","\n","4. **`Variants`:**\n","   - **`ResNet-18 and ResNet-34`:** These use basic residual blocks and are shallower. They are quicker to train and good for simpler tasks.\n","   - **`ResNet-50, ResNet-101, ResNet-152`:** These use bottleneck blocks and are much deeper. They achieve higher accuracy and are suitable for complex tasks.\n","\n","##### **Summary:**\n","ResNet‚Äôs main innovation is the use of residual blocks with skip connections, which make it easier to train very deep networks by solving the vanishing gradient problem. This allows networks like `ResNet-50` and `ResNet-101` to be both deep and effective, achieving high performance on tasks like image classification.\n","\n","\n","### `VGG` (Visual Geometry Group) Network.\n","\n","<img src=\"data:image/png;base64,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\" alt=\"Example Image\" width=\"500\">\n","\n","\n","### What is `VGG`?\n","`VGG,` developed by the Visual Geometry Group at Oxford, is a well-known deep learning model that‚Äôs praised for its simplicity and effectiveness. It was introduced in a 2014 paper and focuses on deepening the network by using very small convolutional filters.\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:1400/1*VPm-hHOM14OisbFUU4cL6Q.png\" alt=\"Example Image\" width=\"700\">\n","\n","\n","##### **Key Features of `VGG`.**\n","1. **`Simple Architecture`:**\n","   - **`Convolutional Layers`:** VGG networks use very small (3x3) convolutional filters. This simplicity contrasts with other networks that use larger filters. The idea is that stacking several small filters can achieve the same receptive field as a single larger filter.\n","   - **`Pooling Layers`:** After a series of convolutional layers, max pooling layers (usually 2x2 with stride 2) are used to downsample the feature maps and reduce their spatial dimensions.\n","\n","2. **`Architecture Structure`:**\n","   - **`VGG-16 and VGG-19`:** These are the two most popular variants. `VGG-16` has 16 weight layers (13 convolutional and 3 fully connected), while `VGG-19` has 19 weight layers (16 convolutional and 3 fully connected).\n","   - **`Layers`:**\n","     - **`Convolutional Layers`:** Stacked in a sequence, usually with increasing depth.\n","     - **`Max Pooling`:** Applied after groups of convolutional layers to reduce the spatial size of feature maps.\n","     - **`Fully Connected Layers`:** At the end, the flattened output from the convolutional layers is passed through fully connected layers for classification.\n","\n","3. **`Variants`:**\n","   - **`VGG-16`:** Contains 13 convolutional layers and 3 fully connected layers. It‚Äôs known for its relatively deep architecture with a manageable number of parameters.\n","   - **`VGG-19`:** Similar to VGG-16 but with 19 layers, providing even deeper feature extraction.\n","\n","##### **Summary:**\n","`VGG` is known for its straightforward and effective architecture, using small 3x3 convolutional filters and pooling layers to create deep networks. The simplicity of `VGG-16` and `VGG-19` makes them popular for many image recognition tasks, providing a good balance of depth and computational efficiency.\n","\n","\n","Both `ResNet` and `VGG` have made significant impacts on deep learning by addressing different challenges: `ResNet` with its deep architectures and residual learning, and `VGG` with its simplicity and depth. Each has its strengths, making them valuable tools for various computer vision tasks.\n","\n","\n","### How they work in simple terms?\n","\n","**`ResNet` (Residual Network)** is designed to tackle the challenges of training very deep neural networks through the use of residual blocks. Each residual block contains convolutional layers with skip connections that bypass one or more layers, adding the input directly to the output. This helps gradients flow more easily during backpropagation, addressing the vanishing gradient problem and allowing for deeper networks like `ResNet-50` and `ResNet-101`. The addition of these skip connections enables the network to learn more complex features without degrading performance, making` ResNet particularly effective for complex tasks and large datasets.\n","\n","**`VGG` (Visual Geometry Group)** focuses on using very small 3x3 convolutional filters stacked in a deep network, combined with max pooling layers to downsample the data. This architecture emphasizes simplicity and depth, with networks like `VGG-16` and `VGG-19` comprising multiple convolutional layers followed by fully connected layers for classification. By using small filters and deep stacking, `VGG` effectively captures hierarchical features while maintaining a straightforward design, making it a popular choice for transfer learning and feature extraction in various computer vision applications.\n","\n","\n","\n","To Load this two pretrained models, we can use the `torchvision` library, which provides pretrained models ready for use. The only thing that we might have to adjust is the final layers, which changes in each different classification problem, accordingly to the number of classes it. This process of adjusting the final layers of the pretain model to be ready for use for another cv task is called ***fine-tuning*** and we will take a closer look of it in the next chapter."],"metadata":{"id":"aA79HQZI5wc8"}},{"cell_type":"code","source":["import torch\n","import torchvision.models as models\n","\n","# Load the ResNet-50 model\n","resnet50 = models.resnet50(pretrained=True)\n","\n","# Load the VGG-16 model\n","vgg16 = models.vgg16(pretrained=True)\n","\n","# Set the models to evaluation mode (important for inference)\n","resnet50.eval()\n","vgg16.eval()\n","\n","# Example: Print the architecture of ResNet-50\n","print(resnet50)\n","\n","# Example: Print the architecture of VGG-16\n","print(vgg16)\n"],"metadata":{"id":"nmPFOCxfpIEP"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##### **Break the code ü™®.**\n","- `Pre-trained models`: By setting `pretrained=True`, the models are loaded with weights pre-trained on the ImageNet dataset. This makes them ready for transfer learning or feature extraction.\n","- `Evaluation mode`: The `eval()` method is called to set the models to evaluation mode, which is important when using the models for inference (e.g., turning off dropout and batch normalization behaviors specific to training)."],"metadata":{"id":"BBFVlewopXyq"}},{"cell_type":"markdown","source":["## [5. Fine-Tuning.]()\n","\n","<img src=\"https://www.labellerr.com/blog/content/images/2023/08/6488323befb01b8fac0fe171_VmVuJPKbeUxwrJcqoQ5EYZOSWGiW2rE-C_Yj563jJAQrE2V8PP1ibzWUrXrDLXzJIl7i205vzAfQKRL53whzjrBJKXtP8J9j4J_Pn9vtAh-o9sxEUAIPxHYZgNuJyvOXleZZDzTxr8sIh371Xznqwn8.png\" alt=\"Example Image\" width=\"600\">\n","\n","\n","Fine-tuning is the process of taking a model that has already been trained on a large dataset (like `ImageNet`) and adapting it to work well on a different, often smaller, dataset. This is done by continuing the training process, but now with the new dataset in mind. The idea is to leverage the features that the model has already learned and apply them to the new task.\n","\n","### Why and When to Fine-Tune?\n","Fine-tuning is especially useful when you don‚Äôt have a lot of data for your new task. Instead of training a model from scratch (which would require a large amount of data and computational resources), you start with a model that already understands many basic features of images, like edges, textures, and shapes. If your new task is similar to the original one (like recognizing objects in images), fine-tuning helps you achieve good performance even with limited data.\n","\n","\n","##### **Fine-Tuning Strategies:**\n","Let's explore three common fine-tuning strategies: `End-to-End Fine-Tuning`, `Freezing Parameters`, and `Selective Layer Fine-Tuning`.\n","\n","1. **`End-to-End Fine-Tuning`**: End-to-end fine-tuning involves training the entire network on your new dataset. This means that all the weights in the model, from the first layer to the last, are updated during training.\n","    - `When to Use`:\n","        - `Large Dataset`: You have a large enough dataset similar to the one the model was originally trained on (like `ImageNet)`.\n","        - `New task complexity`: The new task is complex and might require fine-tuning of all layers for the model to adapt properly.\n","    - `Advantages`:\n","        - Allows the model to fully adapt to new data.\n","        - Can potentially lead the best performance on the new task if done correctly.\n","    - `Disadvantages`:\n","        - Computationally expensive.\n","        - Risk of overfitting, especially if the new dataset is small.\n","    ```python\n","    # Load the pretrained model\n","    model = models.resnet50(pretrained=True)\n","    # Modify the final layer for your specific task\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 10)  ## Because CIFAR-10 has 10 classes\n","    ```\n","2. **`Freezing Parameters`**: Freezing parameters means keeping certain layers of the pre-trained model fixed (i.e., not updating their weights during training) while fine-tuning only the last few layers. Typically, the early layers, which capture general features like edges and textures, are frozen.\n","    - `When to Use`:\n","        - `Small Dataset`: Your new dataset is small, and you want to avoid overfitting.`.\n","        - `Similarity to original task`: The new task is somewhat similar to the original task, so the early features are still relevant.\n","    - `Advantages`:\n","        - Reduces the risk of overfitting.\n","        - Saves computational resources by reducing the number of parameters to update.\n","        - Faster training.\n","    - `Disadvantages`:\n","        - Might not fully adapt to the new task if the new dataset is significantly different.\n","    ```python\n","    # Load the pretrained model\n","    model = models.resnet50(pretrained=True)\n","    # Freeze all layers except the last one\n","    for param in model.parameters():\n","        param.requires_grad = False\n","    # Modify the final layer for your specific task\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 10)  # Because CIFAR-10 has 10 classes\n","    ```\n","3. **`Selective Layer Fine-Tuning`**: Selective layer fine-tuning involves freezing some layers of the model while allowing others to be fine-tuned. Typically, you freeze the very early layers, fine-tune some of the middle layers, and fully fine-tune the last few layers.\n","    - `When to Use`:\n","        - `Moderate Dataset size`: When you have a moderately sized dataset and need a balance between the two previous approaches.\n","        - `Need for partial adaptation`: The new task requires some adaptation, but the early features are still mostly relevant.\n","    - `Advantages`:\n","        - Provides a balance between adaptation and avoiding overfitting.\n","        - Can lead to better performance than freezing all early layers while still being computationally efficient.\n","    - `Disadvantages`:\n","        - Requires more careful tuning to determine which layers to freeze and which to fine-tune.\n","    ```python\n","    # Load the pretrained model\n","    model = models.resnet50(pretrained=True)\n","    # Freeze the first few layers\n","    for name, param in model.named_parameters():\n","        if \"layer1\" in name or \"layer2\" in name:  # Freeze these layers\n","            param.requires_grad = False\n","    # Modify the final layer for your specific task\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 10)  # Because CIFAR-10 has 10 classes\n","    ```\n","\n","### Summary:\n","1. `End-to-End Fine-Tuning`: Adapts the entire model, ideal for large datasets and complex tasks.\n","2. `Freezing Parameters`: Fine-tunes only the last layer(s), reducing overfitting risks, best for small datasets.\n","3. `Selective Layer Fine-Tuning`: A middle ground, fine-tuning some layers while freezing others, balancing performance and overfitting.\n","\n","Each of these fine-tuning strategies can be tailored to fit your specific needs, whether you're working with limited data, trying to save on computational resources, or dealing with a unique dataset. By getting familiar with these techniques and knowing when to use them, you can effectively leverage pre-trained models to tackle a wide variety of tasks. This hands-on approach lets you get the best performance out of your models, no matter the challenge you're facing."],"metadata":{"id":"9zRd55v5rDu5"}},{"cell_type":"markdown","source":["## [6. Optimization & Hyper-parameter Tuning (HPT).]()\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:1142/1*5mStLTnIxsANpOHSwAFJhg.png\" alt=\"Example Image\" width=\"600\">\n","\n","\n","### What are Hyper-parameters (`HPs`)?\n","`Hyper-parameters` are crucial settings that control the training process of a machine learning model. Unlike parameters, which the model learns during training (like weights and biases), `hyper-parameters` are set before the training starts and directly influence how the model learns. They include aspects like the learning rate, batch size, number of epochs, and more. Choosing the right `hyper-parameters` can significantly impact the model's performance, making the difference between a well-generalized model and one that overfits or underperforms.\n","\n","### Most common `HPs`.\n","When training a `machine learning model`, particularly deep learning models, several `hyper-parameters` play a critical role in determining the performance, efficiency, and generalization of the model. Here's a more detailed list of the most common hyper-parameters you might need to tune:\n","\n","1. `Learning Rate`: **`Purpose:`**  Controls the step size at each iteration while moving toward a minimum of the loss function. It determines how much to adjust the model's weights with respect to the loss gradient.**`Impact`**: A high learning rate might lead to a fast convergence but can overshoot the optimal solution, whereas a low learning rate might result in slow convergence and can get stuck in local minima.`Typical Range`: 0.1 to 0.00001.\n","2. `Batch Size`:`Purpose`: Refers to the number of training examples utilized in one iteration to compute the gradient.`Impact`: Smaller batch sizes lead to noisier estimates of the gradient but can result in faster convergence. Larger batch sizes provide more accurate gradients but can slow down the training process and require more memory.`Typical Range`: 16, 32, 64, 128, 256.\n","2. `Number of Epochs`:`Purpose`: Defines how many complete passes the training dataset will go through the learning algorithm.`Impact`: Too few epochs can lead to underfitting, while too many can cause overfitting. Finding the right balance is crucial.`Typical Range`: 10 to 1000, depending on the dataset and model.\n","3. `Dropout Rate`:`Purpose`: A regularization technique that involves randomly setting a fraction of input units to zero at each update during training, which helps prevent overfitting.`Impact`: Higher dropout rates can prevent overfitting but may lead to underfitting if too many neurons are dropped out. Typically used in dense layers and sometimes in convolutional layers.`Typical Range`: 0.2 to 0.5.\n","4. `Number of Layers and Units`:`Purpose`: Determines the architecture of the neural network. This includes the depth (number of layers) and the width (number of neurons/units in each layer).`Impact`: More layers and units can capture more complex patterns but also increase the risk of overfitting and computational cost.`Typical Configurations`: Varies widely depending on the model (e.g., `ResNet`, `VGG`) and task\n","5. `Optimizer`:`Purpose`: The algorithm that adjusts the weights of the model to minimize the loss function. Different optimizers have different characteristics in terms of convergence speed and ability to escape local minima.`Common Types`:\n","    - `SGD (Stochastic Gradient Descent)`: Simple and widely used, often with momentum.\n","    - `Adam (Adaptive Moment Estimation)`: Adaptive learning rates and commonly used due to its good performance in practice.\n","    - `RMSprop`: Adjusts the learning rate based on the average of recent gradients, good for noisy data.\n","\n","`Impact`: The choice of optimizer can significantly affect convergence and model performance.\n","6. `Loss Function`:`Purpose`: Measures how well the model's predictions match the actual labels. The loss function guides the optimizer on how to adjust the model‚Äôs weights.`Common Types`:\n","    - `Cross-Entropy Loss`: Commonly used for classification tasks.\n","    - `Mean Squared Error (MSE)`: Used for regression tasks.\n","    - `Hinge Loss`: Often used for \"maximum-margin\" classification, primarily for SVMs.\n","\n","`Impact`: The choice of loss function is crucial as it directly affects how the model learns.\n","7. `Momentum`:\n","    - `Purpose`: A term added to the optimizer that helps accelerate the gradient vectors in the right direction, leading to faster converging.\n","    - `Impact`: Helps smooth out the updates, particularly in noisy gradients, and can prevent the model from getting stuck in local minima.\n","    - `Typical Range`: 0.8 to 0.99.\n","8. `Weight Initialization`:`Purpose`: How the model's initial weights are set before training starts. Proper initialization can prevent issues like vanishing or exploding gradients.`Common Methods`:\n","    - `Xavier Initialization`: Used in tanh or sigmoid activation functions.\n","    - `He Initialization`: Used in ReLU activation functions.\n","    - `Transfer Learning`: nstead of starting with random weights, you start with weights from a pre-trained model that has already learned useful patterns from a large dataset. This is especially useful when you have a smaller dataset for your specific task.\n","\n","`Impact`: Good initialization can lead to faster convergence and better performance.\n","9. `Regularization Parameters`:`Purpose`: Parameters like L1 and L2 regularization add penalties to the loss function to prevent overfitting by encouraging simpler models (smaller weights).`Impact`: Can help the model generalize better by reducing overfitting but may also reduce the capacity of the model if too strong.`Typical Range`: `L2`: 0.0001 to 0.01; `L1`: Less common, but used for sparse models.\n","10. `Learning Rate Scheduler`:`Purpose`: Adjusts the learning rate during training, typically reducing it as training progresses.`Common Strategies`:\n","    - `Step Decay`: Reduces the learning rate by a factor after a fixed number of epochs.\n","    - `Exponential Decay`: Reduces the learning rate exponentially based on epoch count.\n","    - `Cyclical Learning Rates`: Fluctuates the learning rate within a range, improving convergence.\n","\n","`Impact`: Helps the model converge more effectively, especially in later stages of training.\n","11. `Activation Functions`:`Purpose`: The function applied to the output of each neuron to introduce non-linearity into the model.`Common Types`:\n","    - `ReLU (Rectified Linear Unit)`: Most commonly used due to its simplicity and effectiveness.\n","    - `Leaky ReLU`: Variation of ReLU that allows a small gradient when the unit is inactive.\n","    - `Sigmoid`: Useful in binary classification but can cause vanishing gradient problems.\n","    - `Tanh`: Similar to Sigmoid but outputs values between -1 and 1.\n","\n","`Impact`: The choice of activation function can affect the model's ability to learn complex patterns.\n","\n","### How HPs Affect the Model?\n","Hyper-parameters can drastically change a model's behavior. For example, a learning rate that‚Äôs too high might cause the model to converge too quickly to a suboptimal solution, or even diverge. A very low learning rate, on the other hand, might result in extremely slow training. Similarly, choosing the wrong batch size could lead to unstable training or suboptimal performance. Therefore, hyper-parameters not only affect the model‚Äôs accuracy but also the time it takes to train and its ability to generalize to new data.\n","\n","##### **Hyper-parameters vs Parameters.**\n","\n","<img src=\"https://i.ytimg.com/vi/EmiuuebKwY4/maxresdefault.jpg\" alt=\"Example Image\" width=\"500\">\n","\n","\n","It‚Äôs essential to understand the difference between hyper-parameters and parameters:\n","\n","- `Parameters`: These are learned by the model during training, such as the weights and biases in a neural network.\n","- `Hyper-parameters`: These are set before training begins and include settings like the learning rate, batch size, and more. They guide the training process and must be chosen carefully.\n","\n","### What is Hyper-parameter Tuning?\n","`Hyper-parameter tuning` is the process of searching for the optimal hyper-parameters that result in the best performance of your model. It involves experimenting with different combinations of hyper-parameters and evaluating their impact on the model's performance. The goal is to find the hyper-parameter set that maximizes accuracy, minimizes loss, or meets some other criterion relevant to your task.\n","\n","##### **Why We Need HPT?**\n","Proper `hyper-parameter tuning` can lead to significant improvements in model performance. It can help:\n","\n","- `Increase Accuracy`: By finding the best configuration for the model.\n","- `Reduce Overfitting`: By optimizing parameters like dropout rates.\n","- `Speed Up Training`: By choosing efficient batch sizes and learning rates.\n","- `Ensure Better Generalization`: By fine-tuning the model to avoid overfitting to the training data.\n","\n","\n","### How to Tune HPs?\n","#### **`Random Search`.**\n","`Random Search` is a simple yet effective method for hyper-parameter tuning. Instead of exhaustively trying all possible combinations, it samples a random subset of hyper-parameter combinations. This method is particularly useful when you have a large search space and limited computational resources.\n","\n","```python\n","import random\n","\n","# Define a range for each hyperparameter\n","learning_rates = [0.1, 0.01, 0.001, 0.0001]\n","batch_sizes = [16, 32, 64, 128]\n","\n","# Randomly select hyperparameters\n","lr = random.choice(learning_rates)\n","batch_size = random.choice(batch_sizes)\n","\n","print(f'Selected Learning Rate: {lr}')\n","print(f'Selected Batch Size: {batch_size}')\n","```\n","\n","#### **`Grid Search`.**\n","`Grid Search` is a more systematic approach, where you try out every possible combination of hyper-parameters within a predefined grid. It‚Äôs exhaustive and can guarantee finding the best combination within the grid, but it‚Äôs also computationally expensive and not feasible for large search spaces.\n","\n","```python\n","from sklearn.model_selection import GridSearchCV\n","\n","# Define parameter grid\n","param_grid = {\n","    'learning_rate': [0.1, 0.01, 0.001, 0.0001],\n","    'batch_size': [16, 32, 64, 128]\n","}\n","\n","# Perform grid search\n","grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n","grid_search.fit(X_train, y_train)\n","\n","print(f'Best Parameters: {grid_search.best_params_}')\n","```\n","\n","#### **`Bayesian Optimization`.**\n","`Bayesian Optimization` is a more sophisticated technique that builds a probabilistic model of the objective function and uses it to select the most promising hyper-parameters to try next. This method is more efficient than Random or Grid Search, especially for complex models, as it focuses on exploring regions of the search space that are more likely to yield better results.\n","\n","```python\n","from skopt import gp_minimize\n","\n","# Define the function to minimize\n","def objective(params):\n","    learning_rate, batch_size = params\n","    model = build_model(learning_rate, batch_size)\n","    model.fit(X_train, y_train)\n","    score = model.score(X_val, y_val)\n","    return -score\n","\n","# Define parameter space\n","space = [(0.0001, 0.1, 'log-uniform'),  # learning rate\n","         (16, 128)]  # batch size\n","\n","# Perform Bayesian optimization\n","res = gp_minimize(objective, space, n_calls=50, random_state=0)\n","\n","print(f'Best Parameters: {res.x}')\n","```\n","\n","### Which Methodology to Choose?\n","- `Random Search`: Best for large search spaces where you don‚Äôt know which hyper-parameters will have the most significant impact.\n","- `Grid Search`: Ideal for smaller, more controlled search spaces where you can afford the computational cost.\n","- `Bayesian Optimization`: The go-to method for more complex models where efficient, intelligent searching is crucial.\n","\n","By understanding and applying these tuning strategies, you can optimize your model‚Äôs performance, making it more accurate, efficient, and well-suited to the specific task at hand.\n","\n","<img src=\"data:image/png;base64,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\" alt=\"Example Image\" width=\"400\">\n","\n","<img src=\"https://miro.medium.com/v2/resize:fit:1400/0*lu62RCEko0VYe-YZ\" alt=\"Example Image\" width=\"400\">\n","\n","\n","#### üìì **Our HPT Library - `Scikit-Optimize`.**\n","\n","### What is `skopt`?\n","\n","`skopt`, short for **Scikit-Optimize**, is a library that helps you find the best hyperparameters for your machine learning models. Hyperparameters are like the secret ingredients in a recipe‚Äîgetting them right can make a huge difference in how well your model performs. But, finding the right combination by hand is hard and time-consuming. This is where `skopt` comes in.\n","\n","#### How Does `skopt` Work?\n","\n","`skopt` uses smart strategies to explore the hyperparameter space and find the best values. The key technique it uses is **Bayesian Optimization**, where the algorithm tries to predict the best set of parameters based on the results of previous attempts. It doesn't just guess randomly; it learns from each step, making it more efficient than simple methods like grid search or random search.\n","\n","### Key Functions in `skopt`\n","\n","1. **`gp_minimize`**: The main tool for Bayesian Optimization using Gaussian Processes. It helps to find the minimum of a function, which is useful for minimizing loss in machine learning.\n","2. **`space.Real` and `space.Integer`**: These are used to define the range of values that the hyperparameters can take.\n","3. **`objective`**: A function that `skopt` tries to minimize. This function typically takes a set of hyperparameters, runs a model, and returns a score (e.g., accuracy or loss).\n","\n","\n","### Example of Using `skopt` to tune `ResNet-50` for `CIFAR-10` classification.\n","To showcase how to use different hyperparameter optimization techniques with a fine-tuned `ResNet-50` model for `CIFAR-10`, I'll provide an example of using `skopt`.\n","First things first, is needed to define the basic `setup`:\n"],"metadata":{"id":"-BN1Hvljxyli"}},{"cell_type":"code","source":["! pip install scikit-optimize"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JbWA37-Q26Np","executionInfo":{"status":"ok","timestamp":1725901162664,"user_tz":-180,"elapsed":9028,"user":{"displayName":"Despina Ioanna Chalkiadaki","userId":"18085928354633704515"}},"outputId":"2684ded6-51f1-4e9c-f674-30e4baeedbe2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting scikit-optimize\n","  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n","Collecting pyaml>=16.9 (from scikit-optimize)\n","  Downloading pyaml-24.7.0-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n","Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.5.0)\n","Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n","\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pyaml-24.7.0-py3-none-any.whl (24 kB)\n","Installing collected packages: pyaml, scikit-optimize\n","Successfully installed pyaml-24.7.0 scikit-optimize-0.10.2\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision.models import ResNet50_Weights\n","from skopt import gp_minimize\n","from skopt.space import Real, Integer\n","\n","# Define the training and testing transformations\n","transform = transforms.Compose([\n","\t transforms.Resize(224),  # ResNet expects 224x224 input\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n","])\n","\n","# Load the CIFAR-10 dataset.\n","train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n","test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n","\n","# Split the training dataset into training and validation sets (80% train, 20% val).\n","train_size = int(0.8 * len(train_dataset))\n","val_size = len(train_dataset) - train_size\n","train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n","\n","\n","# Load pre-trained ResNet-50 model\n","def build_model(learning_rate):\n","    weights = ResNet50_Weights.DEFAULT\n","    model = torchvision.models.resnet50(weights=weights)\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 10)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    return model, optimizer\n","\n","# Define the objective function\n","def objective(params):\n","    learning_rate, batch_size = params\n","\n","    # Ensure batch_size is a positive integer\n","    batch_size = int(batch_size)\n","    if batch_size <= 0:\n","        return float('inf')  # Return a large loss for invalid batch size\n","\n","    # Adjust the data loader with the new batch size\n","    train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n","\n","\n","    model, optimizer = build_model(learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","    model.to(device)\n","\n","    # Training loop (simple example with 1 epoch)\n","    model = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n","\n","    # Evaluate on the test set\n","    acc, conf = evaluate_model(model, test_loader, device)\n","    return -acc # Negative because we want to maximize accuracy\n","\n","# Define the search space with Integer for batch_size\n","space = [Real(0.0001, 0.01, prior='log-uniform'),  # Learning rate\n","         Integer(16, 128)]  # Batch size\n","\n","# Perform Bayesian optimization\n","res = gp_minimize(objective, space, n_calls=10, random_state=0)\n","\n","# Output the best parameters\n","print(f'Best Parameters: Learning Rate = {res.x[0]}, Batch Size = {res.x[1]}')\n"],"metadata":{"id":"BFGHcCqI23Cg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["So, now let me explain each code block in great detail, to undesrstand exactly how `skopt` works.\n","\n","##### **Break the code ü™®.**\n","\n","#### 1. **Setting Up the Dataset.**\n","```python\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from skopt import gp_minimize\n","from skopt.space import Real, Integer\n","```\n","This imports the necessary libraries: `torch` and `torchvision` for handling the deep learning tasks, and `skopt` for optimizing the hyperparameters.\n","\n","#### 2. **Data Preprocessing.**\n","```python\n","transform = transforms.Compose(\n","    [transforms.Resize(224),  # ResNet expects 224x224 input\n","     transforms.ToTensor(),\n","     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n","\n","trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n","                                        download=True, transform=transform)\n","testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n","                                       download=True, transform=transform)\n","```\n","- **`Goal`**: Prepare the `CIFAR-10` dataset for training a ResNet model.\n","- **`Explanation`**: The `transform` resizes the images to 224x224 pixels (because ResNet expects this size), converts them to tensors, and normalizes the pixel values. Then, the `CIFAR-10` dataset is loaded with these transformations applied.\n","\n","#### 3. **Building the Model.**\n","```python\n","def build_model(learning_rate):\n","    model = torchvision.models.resnet50(pretrained=True)\n","    num_ftrs = model.fc.in_features\n","    model.fc = nn.Linear(num_ftrs, 10)\n","    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","    return model, optimizer\n","```\n","- **`Goal`**: Create a ResNet-50 model customized for `CIFAR-10`.\n","- **`Explanation`**: The model is pre-trained on another dataset (`ImageNet`), and then we replace its final layer to fit the 10 classes of `CIFAR-10`. The learning rate is set for the `Adam` optimizer, which will be tuned by `skopt`.\n","\n","#### 4. **Objective Function**\n","```python\n","def objective(params):\n","    learning_rate, batch_size = params\n","    \n","    batch_size = int(batch_size)\n","    if batch_size <= 0:\n","        return float('inf')  # Return a large loss for invalid batch size\n","\n","    trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n","    testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n","\n","    model, optimizer = build_model(learning_rate)\n","    criterion = nn.CrossEntropyLoss()\n","\n","    model.train()\n","    for epoch in range(1):  # You can increase the number of epochs\n","        running_loss = 0.0\n","        for i, data in enumerate(trainloader, 0):\n","            inputs, labels = data\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","    \n","    model.eval()\n","    correct = 0\n","    total = 0\n","    with torch.no_grad():\n","        for data in testloader:\n","            images, labels = data\n","            outputs = model(images)\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    accuracy = correct / total\n","    return -accuracy  # Negative because we want to maximize accuracy\n","```\n","- **`Goal`**: This is the function `skopt` tries to minimize.\n","- **`Explanation`**: It takes a pair of hyperparameters (`learning_rate` and `batch_size`), builds a model, trains it for one epoch, and then checks its accuracy on the test set. Since `gp_minimize` tries to minimize the objective, we return the negative accuracy‚Äîso maximizing accuracy is equivalent to minimizing the negative value.\n","\n","#### 5. **Defining the Hyperparameter Space.**\n","```python\n","space = [Real(0.0001, 0.01, prior='log-uniform'),  # Learning rate\n","         Integer(16, 128)]  # Batch size\n","```\n","- **`Goal`**: Define the search space for `learning_rate` and `batch_size`.\n","- **`Explanation`**:\n","  - `Real(0.0001, 0.01, prior='log-uniform')` tells `skopt` to search for the learning rate in a range between 0.0001 and 0.01. `log-uniform` means it will sample values more evenly across orders of magnitude.\n","  - `Integer(16, 128)` specifies that the batch size should be an integer between 16 and 128.\n","\n","#### 6. **Running the Optimization.**\n","```python\n","res = gp_minimize(objective, space, n_calls=10, random_state=0)\n","```\n","- **`Goal`**: Find the best hyperparameters using Bayesian Optimization.\n","- **`Explanation`**:\n","  - `gp_minimize` runs the `objective` function 10 times (`n_calls=10`), each time trying a new set of hyperparameters within the defined space.\n","  - `random_state=0` ensures reproducibility.\n","\n","#### 7. **Getting the Results.**\n","```python\n","print(f'Best Parameters: Learning Rate = {res.x[0]}, Batch Size = {res.x[1]}')\n","```\n","- **`Goal`**: Print out the best hyperparameters found.\n","- **`Explanation`**: After the optimization process, `res.x` contains the best learning rate and batch size found during the search.\n","\n","#### **Conclusion.**\n","\n","- **`skopt`** is a powerful tool to automate the process of hyperparameter tuning using smart, learning-based strategies.\n","- **The code**: Loads a `CIFAR-10` dataset, defines a `ResNet-50`model, and then uses `skopt` to find the best learning rate and batch size by optimizing the accuracy of the model on the test set.\n","- **Outcome**: After running this, you'll know the best learning rate and batch size for training a `ResNet-50` model on the `CIFAR-10` dataset, which maximizes its accuracy.\n","\n","And that‚Äôs how you can use `skopt` to improve your machine learning recipes! üéØ"],"metadata":{"id":"-mlO-Roz3NVJ"}},{"cell_type":"markdown","source":["## [7. Overall Sum Up and Further Explanation.]()\n","\n","In this tutorial üéì, we took a deep dive into the world of Convolutional Neural Networks (CNNs) and Hyperparameter Tuning using `PyTorch`. Here‚Äôs a quick recap to wrap things up nicely! üéÅ\n","\n","##### **Convolutional Neural Networks.** üß†\n","We started by understanding what CNNs are and why they're such a big deal in the world of deep learning, especially for image-related tasks. CNNs are like the superheroes ü¶∏‚Äç‚ôÇÔ∏è of deep neural networks, designed to recognize patterns in images through layers like convolutional, pooling, and fully connected layers.\n","\n","- `Convolutional Layers`: These are the keen eyes üëÄ of the network, spotting edges, textures, and intricate patterns within the images.\n","- `Pooling Layers`: They act like a zoom-out lens üîç, reducing the size of the feature maps while retaining important information, speeding up the network, and preventing overfitting.\n","- `Fully Connected Layers`: At the end of the network, these layers act as the final decision-makers üß†, combining all the learned features to make accurate predictions.\n","\n","##### **Building a CNN in `PyTorch`.** üõ†Ô∏èüêç\n","We then built a 9-layer CNN from scratch in `PyTorch`, which involved defining the architecture üè¶, loading and transforming the `CIFAR-10` dataset, and training the model. By the end, we had a working model that could classify images from `CIFAR-10`, a popular dataset for small image classification tasks üñºÔ∏è.\n","\n","##### **Pretrained Models.** üöÄ\n","To save time and resources, we explored the concept of pretrained models, focusing on architectures like `ResNet` and `VGG`, which have been trained on the massive `ImageNet` üñºÔ∏è dataset. These models serve as powerful starting points for many computer vision tasks.\n","\n","- **`ResNet`** with its skip connections helps in training very deep networks without losing gradient flow.\n","- **`VGG`** is simple yet effective, known for using small 3x3 filters consistently across all its layers.\n","\n","We fine-tuned a `ResNet-50` model on `CIFAR-10`, showing how you can adapt these models to new tasks with just a few tweaks.\n","\n","#### **Hyperparameter Tuning.** üéØ\n","Finally, we delved into Hyperparameter Tuning -- the art üé® of finding the best settings for training your model. We discussed different strategies like `Random Search` üé≤, `Grid Search` üîç, and `Bayesian Optimization` üìà, each with its own pros and cons. Proper tuning can be the difference between a good model and a great one! üåü\n","\n","We also took a tiny look to `skopt` one of the best biginner friendly libraries for Hyperparameter Tuning, and one of my personal favourites.\n","\n","##### **Why It Matters?** ü§îüåç\n","Understanding CNNs and how to implement them in `PyTorch` is crucial for anyone looking to work in the field of computer vision. Whether you‚Äôre building models from scratch or fine-tuning existing ones üîë , this knowledge forms the foundation of many cutting-edge technologies, from facial recognition üò∂ to self-driving cars üöó.\n","\n","By mastering these concepts, you‚Äôre not just learning to code; you‚Äôre equipping yourself with tools to solve real-world problems using AI. So keep experimenting, keep tuning, and most importantly, keep learning! üöÄ\n","\n","\n","Feel free to revisit any section if you need a refresher, and happy coding! üë®‚Äçüíªüë©‚Äçüíª"],"metadata":{"id":"yfTRzO-zN4pu"}}]}